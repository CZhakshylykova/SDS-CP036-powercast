{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da6bf27",
   "metadata": {},
   "source": [
    "# Phase 2 - Feature Engineering & Deep Learning Prep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98b639",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21c6ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d5425",
   "metadata": {},
   "source": [
    "### Loading 'cleaned' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538be7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>WS</th>\n",
       "      <th>GDF</th>\n",
       "      <th>DF</th>\n",
       "      <th>PZ1</th>\n",
       "      <th>PZ2</th>\n",
       "      <th>PZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>6.559</td>\n",
       "      <td>73.8</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.119</td>\n",
       "      <td>34055.69620</td>\n",
       "      <td>16128.87538</td>\n",
       "      <td>20240.96386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 00:10:00</td>\n",
       "      <td>6.414</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.085</td>\n",
       "      <td>29814.68354</td>\n",
       "      <td>19375.07599</td>\n",
       "      <td>20131.08434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 00:20:00</td>\n",
       "      <td>6.313</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.100</td>\n",
       "      <td>29128.10127</td>\n",
       "      <td>19006.68693</td>\n",
       "      <td>19668.43373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 00:30:00</td>\n",
       "      <td>6.121</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.096</td>\n",
       "      <td>28228.86076</td>\n",
       "      <td>18361.09422</td>\n",
       "      <td>18899.27711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 00:40:00</td>\n",
       "      <td>5.921</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.085</td>\n",
       "      <td>27335.69620</td>\n",
       "      <td>17872.34043</td>\n",
       "      <td>18442.40964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime   temp  humidity     WS    GDF     DF          PZ1  \\\n",
       "0 2017-01-01 00:00:00  6.559      73.8  0.083  0.051  0.119  34055.69620   \n",
       "1 2017-01-01 00:10:00  6.414      74.5  0.083  0.070  0.085  29814.68354   \n",
       "2 2017-01-01 00:20:00  6.313      74.5  0.080  0.062  0.100  29128.10127   \n",
       "3 2017-01-01 00:30:00  6.121      75.0  0.083  0.091  0.096  28228.86076   \n",
       "4 2017-01-01 00:40:00  5.921      75.7  0.081  0.048  0.085  27335.69620   \n",
       "\n",
       "           PZ2          PZ3  \n",
       "0  16128.87538  20240.96386  \n",
       "1  19375.07599  20131.08434  \n",
       "2  19006.68693  19668.43373  \n",
       "3  18361.09422  18899.27711  \n",
       "4  17872.34043  18442.40964  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"new_data.csv\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95235933",
   "metadata": {},
   "source": [
    "### Extracting time-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa245d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>WS</th>\n",
       "      <th>GDF</th>\n",
       "      <th>DF</th>\n",
       "      <th>PZ1</th>\n",
       "      <th>PZ2</th>\n",
       "      <th>PZ3</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>6.559</td>\n",
       "      <td>73.8</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.119</td>\n",
       "      <td>34055.69620</td>\n",
       "      <td>16128.87538</td>\n",
       "      <td>20240.96386</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 00:10:00</td>\n",
       "      <td>6.414</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.085</td>\n",
       "      <td>29814.68354</td>\n",
       "      <td>19375.07599</td>\n",
       "      <td>20131.08434</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 00:20:00</td>\n",
       "      <td>6.313</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.100</td>\n",
       "      <td>29128.10127</td>\n",
       "      <td>19006.68693</td>\n",
       "      <td>19668.43373</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 00:30:00</td>\n",
       "      <td>6.121</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.096</td>\n",
       "      <td>28228.86076</td>\n",
       "      <td>18361.09422</td>\n",
       "      <td>18899.27711</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 00:40:00</td>\n",
       "      <td>5.921</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.085</td>\n",
       "      <td>27335.69620</td>\n",
       "      <td>17872.34043</td>\n",
       "      <td>18442.40964</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime   temp  humidity     WS    GDF     DF          PZ1  \\\n",
       "0 2017-01-01 00:00:00  6.559      73.8  0.083  0.051  0.119  34055.69620   \n",
       "1 2017-01-01 00:10:00  6.414      74.5  0.083  0.070  0.085  29814.68354   \n",
       "2 2017-01-01 00:20:00  6.313      74.5  0.080  0.062  0.100  29128.10127   \n",
       "3 2017-01-01 00:30:00  6.121      75.0  0.083  0.091  0.096  28228.86076   \n",
       "4 2017-01-01 00:40:00  5.921      75.7  0.081  0.048  0.085  27335.69620   \n",
       "\n",
       "           PZ2          PZ3  hour  day_of_week  month  day_of_year  \n",
       "0  16128.87538  20240.96386     0            6      1            1  \n",
       "1  19375.07599  20131.08434     0            6      1            1  \n",
       "2  19006.68693  19668.43373     0            6      1            1  \n",
       "3  18361.09422  18899.27711     0            6      1            1  \n",
       "4  17872.34043  18442.40964     0            6      1            1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day_of_year'] = df['datetime'].dt.dayofyear\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280504f",
   "metadata": {},
   "source": [
    "## Lookback Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac35a37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different lookback window sizes:\n",
      "Lookback 6: X shape (52410, 6, 12), y shape (52410, 1, 12)\n",
      "  ✅ No NaN values in window 6\n",
      "Lookback 12: X shape (52404, 12, 12), y shape (52404, 1, 12)\n",
      "  ✅ No NaN values in window 12\n",
      "Lookback 24: X shape (52392, 24, 12), y shape (52392, 1, 12)\n",
      "  ✅ No NaN values in window 24\n",
      "Lookback 48: X shape (52368, 48, 12), y shape (52368, 1, 12)\n",
      "  ✅ No NaN values in window 48\n",
      "Lookback 96: X shape (52320, 96, 12), y shape (52320, 1, 12)\n",
      "  ✅ No NaN values in window 96\n",
      "\n",
      "Selected optimal lookback window: 24 time steps\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, lookback_window, target_cols=None, forecast_horizon=1):\n",
    "    \"\"\"\n",
    "    Create sequences for time series forecasting\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with time series data\n",
    "        lookback_window: Number of time steps to look back\n",
    "        target_cols: Columns to predict (default: all numeric columns)\n",
    "        forecast_horizon: Number of steps ahead to predict\n",
    "    \n",
    "    Returns:\n",
    "        X: Input sequences (samples, lookback_window, features)\n",
    "        y: Target values (samples, forecast_horizon, targets)\n",
    "    \"\"\"\n",
    "    if target_cols is None:\n",
    "        # Exclude datetime and index columns\n",
    "        target_cols = [col for col in data.columns if col not in ['datetime', 'Unnamed: 0']]\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(lookback_window, len(data) - forecast_horizon + 1):\n",
    "        # Input sequence\n",
    "        X.append(data[target_cols].iloc[i-lookback_window:i].values)\n",
    "        \n",
    "        # Target sequence\n",
    "        y.append(data[target_cols].iloc[i:i+forecast_horizon].values)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Test different lookback window sizes\n",
    "lookback_windows = [6, 12, 24, 48, 96]  # 1 hour, 2 hours, 4 hours, 8 hours, 16 hours\n",
    "print(\"Testing different lookback window sizes:\")\n",
    "\n",
    "for window in lookback_windows:\n",
    "    X, y = create_sequences(df, window)\n",
    "    print(f\"Lookback {window}: X shape {X.shape}, y shape {y.shape}\")\n",
    "    \n",
    "    # Check for any NaN values\n",
    "    if np.isnan(X).any() or np.isnan(y).any():\n",
    "        print(f\"  ⚠️  Warning: NaN values found in window {window}\")\n",
    "    else:\n",
    "        print(f\"  ✅ No NaN values in window {window}\")\n",
    "\n",
    "# Choose optimal lookback window (24 time steps = 4 hours)\n",
    "OPTIMAL_LOOKBACK = 24\n",
    "print(f\"\\nSelected optimal lookback window: {OPTIMAL_LOOKBACK} time steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ba7ff",
   "metadata": {},
   "source": [
    "## Normalization + Cyclical Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d15edeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added cyclical features:\n",
      "['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
      "\n",
      "Features to scale: 16\n",
      "Feature columns: ['temp', 'humidity', 'WS', 'GDF', 'DF', 'PZ1', 'PZ2', 'PZ3', 'hour_sin', 'hour_cos']...\n",
      "\n",
      "Training data size: 36691\n",
      "Total data size: 52416\n",
      "\n",
      "Scaling completed. Sample of scaled features:\n",
      "       temp  humidity        WS       GDF        DF\n",
      "0 -2.051356  0.382024 -0.812344 -0.726609 -0.636040\n",
      "1 -2.074813  0.425550 -0.812344 -0.726542 -0.636291\n",
      "2 -2.091152  0.425550 -0.813616 -0.726570 -0.636180\n",
      "3 -2.122213  0.456640 -0.812344 -0.726469 -0.636210\n",
      "4 -2.154568  0.500166 -0.813192 -0.726619 -0.636291\n"
     ]
    }
   ],
   "source": [
    "def create_cyclical_features(data):\n",
    "    \"\"\"Create cyclical time features using sine/cosine transformations\"\"\"\n",
    "    data_cyclical = data.copy()\n",
    "    \n",
    "    # Hour of day (24-hour cycle)\n",
    "    data_cyclical['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "    data_cyclical['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "    \n",
    "    # Day of week (7-day cycle)\n",
    "    data_cyclical['day_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "    data_cyclical['day_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "    \n",
    "    # Month of year (12-month cycle)\n",
    "    data_cyclical['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "    data_cyclical['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "    \n",
    "    # Day of year (365-day cycle)\n",
    "    data_cyclical['day_of_year_sin'] = np.sin(2 * np.pi * data['day_of_year'] / 365)\n",
    "    data_cyclical['day_of_year_cos'] = np.cos(2 * np.pi * data['day_of_year'] / 365)\n",
    "    \n",
    "    return data_cyclical\n",
    "\n",
    "# Create cyclical features\n",
    "df_with_cyclical = create_cyclical_features(df)\n",
    "print(\"Added cyclical features:\")\n",
    "cyclical_cols = [col for col in df_with_cyclical.columns if 'sin' in col or 'cos' in col]\n",
    "print(cyclical_cols)\n",
    "\n",
    "# Separate features for scaling\n",
    "feature_cols = [col for col in df_with_cyclical.columns \n",
    "                if col not in ['datetime', 'Unnamed: 0', 'hour', 'day_of_week', 'month', 'day_of_year']]\n",
    "\n",
    "print(f\"\\nFeatures to scale: {len(feature_cols)}\")\n",
    "print(f\"Feature columns: {feature_cols[:10]}...\")  # Show first 10\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_X = StandardScaler()  # For input features\n",
    "scaler_y = StandardScaler()  # For target variables\n",
    "\n",
    "# Fit scalers on training data only (to prevent data leakage)\n",
    "train_size = int(0.7 * len(df_with_cyclical))\n",
    "train_data = df_with_cyclical.iloc[:train_size]\n",
    "\n",
    "print(f\"\\nTraining data size: {train_size}\")\n",
    "print(f\"Total data size: {len(df_with_cyclical)}\")\n",
    "\n",
    "# Fit scalers on training data\n",
    "scaler_X.fit(train_data[feature_cols])\n",
    "scaler_y.fit(train_data[feature_cols])\n",
    "\n",
    "# Scale all data\n",
    "df_scaled = df_with_cyclical.copy()\n",
    "df_scaled[feature_cols] = scaler_X.transform(df_with_cyclical[feature_cols])\n",
    "\n",
    "print(\"\\nScaling completed. Sample of scaled features:\")\n",
    "print(df_scaled[feature_cols[:5]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66ae66",
   "metadata": {},
   "source": [
    "## Convert to Tensors / train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6939cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split sizes:\n",
      "Training: 36691 (70.0%)\n",
      "Validation: 7862 (15.0%)\n",
      "Test: 7863 (15.0%)\n",
      "Total: 52416\n",
      "\n",
      "Split date ranges:\n",
      "Train: 2017-01-01 00:00:00 to 2017-09-12 19:00:00\n",
      "Val: 2017-09-12 19:10:00 to 2017-11-06 09:20:00\n",
      "Test: 2017-11-06 09:30:00 to 2017-12-30 23:50:00\n",
      "\n",
      "Creating sequences with lookback window 24...\n",
      "Sequence shapes:\n",
      "X_train: (36667, 24, 20), y_train: (36667, 1, 20)\n",
      "X_val: (7838, 24, 20), y_val: (7838, 1, 20)\n",
      "X_test: (7839, 24, 20), y_test: (7839, 1, 20)\n",
      "\n",
      "Verifying no data leakage:\n",
      "Training samples: 36667\n",
      "Validation samples: 7838\n",
      "Test samples: 7839\n",
      "Total samples: 52344\n",
      "Expected total: 52392\n"
     ]
    }
   ],
   "source": [
    "# Temporal data splitting (no random shuffling)\n",
    "total_size = len(df_scaled)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Data split sizes:\")\n",
    "print(f\"Training: {train_size} ({train_size/total_size:.1%})\")\n",
    "print(f\"Validation: {val_size} ({val_size/total_size:.1%})\")\n",
    "print(f\"Test: {test_size} ({test_size/total_size:.1%})\")\n",
    "print(f\"Total: {total_size}\")\n",
    "\n",
    "# Split the data\n",
    "train_data = df_scaled.iloc[:train_size]\n",
    "val_data = df_scaled.iloc[train_size:train_size+val_size]\n",
    "test_data = df_scaled.iloc[train_size+val_size:]\n",
    "\n",
    "print(f\"\\nSplit date ranges:\")\n",
    "print(f\"Train: {train_data['datetime'].min()} to {train_data['datetime'].max()}\")\n",
    "print(f\"Val: {val_data['datetime'].min()} to {val_data['datetime'].max()}\")\n",
    "print(f\"Test: {test_data['datetime'].min()} to {test_data['datetime'].max()}\")\n",
    "\n",
    "# Create sequences for each split\n",
    "print(f\"\\nCreating sequences with lookback window {OPTIMAL_LOOKBACK}...\")\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, OPTIMAL_LOOKBACK)\n",
    "X_val, y_val = create_sequences(val_data, OPTIMAL_LOOKBACK)\n",
    "X_test, y_test = create_sequences(test_data, OPTIMAL_LOOKBACK)\n",
    "\n",
    "print(f\"Sequence shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Verify no data leakage between splits\n",
    "print(f\"\\nVerifying no data leakage:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Total samples: {len(X_train) + len(X_val) + len(X_test)}\")\n",
    "print(f\"Expected total: {total_size - OPTIMAL_LOOKBACK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc956920",
   "metadata": {},
   "source": [
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecea975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes and types:\n",
      "X_train: torch.Size([36667, 24, 20]), dtype: torch.float32\n",
      "y_train: torch.Size([36667, 1, 20]), dtype: torch.float32\n",
      "X_val: torch.Size([7838, 24, 20]), dtype: torch.float32\n",
      "y_val: torch.Size([7838, 1, 20]), dtype: torch.float32\n",
      "X_test: torch.Size([7839, 24, 20]), dtype: torch.float32\n",
      "y_test: torch.Size([7839, 1, 20]), dtype: torch.float32\n",
      "\n",
      "Feature-target alignment verification:\n",
      "Input features: 20\n",
      "Target features: 20\n",
      "Lookback window: 24\n",
      "Forecast horizon: 1\n",
      "\n",
      "Data quality check:\n",
      "X_train NaN: False\n",
      "y_train NaN: False\n",
      "X_train Inf: False\n",
      "y_train Inf: False\n",
      "\n",
      "Sample input sequence (first 3 time steps, first 5 features):\n",
      "tensor([[-2.0514,  0.3820, -0.8123, -0.7266, -0.6360],\n",
      "        [-2.0748,  0.4255, -0.8123, -0.7265, -0.6363],\n",
      "        [-2.0912,  0.4255, -0.8136, -0.7266, -0.6362]])\n",
      "\n",
      "Sample target (first 3 time steps, first 5 features):\n",
      "tensor([[-2.3435,  0.5002, -0.8123, -0.7266, -0.6359]])\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "print(\"Tensor shapes and types:\")\n",
    "print(f\"X_train: {X_train_tensor.shape}, dtype: {X_train_tensor.dtype}\")\n",
    "print(f\"y_train: {y_train_tensor.shape}, dtype: {y_train_tensor.dtype}\")\n",
    "print(f\"X_val: {X_val_tensor.shape}, dtype: {y_val_tensor.dtype}\")\n",
    "print(f\"y_val: {y_val_tensor.shape}, dtype: {y_val_tensor.dtype}\")\n",
    "print(f\"X_test: {X_test_tensor.shape}, dtype: {y_test_tensor.dtype}\")\n",
    "print(f\"y_test: {y_test_tensor.shape}, dtype: {y_test_tensor.dtype}\")\n",
    "\n",
    "# Verify alignment\n",
    "print(f\"\\nFeature-target alignment verification:\")\n",
    "print(f\"Input features: {X_train_tensor.shape[2]}\")\n",
    "print(f\"Target features: {y_train_tensor.shape[2]}\")\n",
    "print(f\"Lookback window: {X_train_tensor.shape[1]}\")\n",
    "print(f\"Forecast horizon: {y_train_tensor.shape[1]}\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "print(f\"\\nData quality check:\")\n",
    "print(f\"X_train NaN: {torch.isnan(X_train_tensor).any()}\")\n",
    "print(f\"y_train NaN: {torch.isnan(y_train_tensor).any()}\")\n",
    "print(f\"X_train Inf: {torch.isinf(X_train_tensor).any()}\")\n",
    "print(f\"y_train Inf: {torch.isinf(y_train_tensor).any()}\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nSample input sequence (first 3 time steps, first 5 features):\")\n",
    "print(X_train_tensor[0, :3, :5])\n",
    "print(f\"\\nSample target (first 3 time steps, first 5 features):\")\n",
    "print(y_train_tensor[0, :3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e0a5e",
   "metadata": {},
   "source": [
    "## Custom Dataset & DataLoader Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9143ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset objects created:\n",
      "Train dataset: 36667 samples\n",
      "Validation dataset: 7838 samples\n",
      "Test dataset: 7839 samples\n",
      "\n",
      "DataLoaders created with batch size 32:\n",
      "Training batches: 1146\n",
      "Validation batches: 245\n",
      "Test batches: 245\n",
      "\n",
      "Testing DataLoader functionality:\n",
      "Batch 1:\n",
      "  X shape: torch.Size([32, 24, 20])\n",
      "  y shape: torch.Size([32, 1, 20])\n",
      "  X dtype: torch.float32\n",
      "  y dtype: torch.float32\n",
      "Batch 2:\n",
      "  X shape: torch.Size([32, 24, 20])\n",
      "  y shape: torch.Size([32, 1, 20])\n",
      "  X dtype: torch.float32\n",
      "  y dtype: torch.float32\n",
      "\n",
      "DataLoader test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for time series data\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TimeSeriesDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "print(\"Dataset objects created:\")\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation dataset: {len(val_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_TRAIN = True  # Only shuffle training data\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_TRAIN)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoaders created with batch size {BATCH_SIZE}:\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test the DataLoader\n",
    "print(f\"\\nTesting DataLoader functionality:\")\n",
    "for batch_idx, (batch_X, batch_y) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"  X shape: {batch_X.shape}\")\n",
    "    print(f\"  y shape: {batch_y.shape}\")\n",
    "    print(f\"  X dtype: {batch_X.dtype}\")\n",
    "    print(f\"  y dtype: {batch_y.dtype}\")\n",
    "    if batch_idx >= 1:  # Only show first 2 batches\n",
    "        break\n",
    "\n",
    "print(f\"\\nDataLoader test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d59e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
